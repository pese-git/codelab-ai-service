"""
Application Handler –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ LLM –æ—Ç–≤–µ—Ç–æ–≤.

–ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç use case —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç LLM:
- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
- –í—ã–∑–æ–≤ LLM
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
- –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏–π
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∏–º–∞
"""

import time
import logging
from typing import AsyncGenerator, List, Dict, Optional, Any

from ...domain.services.llm_response_processor import LLMResponseProcessor
from ...domain.services.tool_filter_service import ToolFilterService
from ...domain.services.session_management import SessionManagementService
from ...domain.services.hitl_service import HITLService
from ...domain.entities.llm_response import ProcessedResponse
from ...infrastructure.llm.llm_client import LLMClient
from ...infrastructure.events.llm_event_publisher import LLMEventPublisher
from ...models.schemas import StreamChunk

logger = logging.getLogger("agent-runtime.application.stream_llm_response_handler")


class StreamLLMResponseHandler:
    """
    Application Service –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–æ–≤ LLM.
    
    –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç use case —Å—Ç—Ä–∏–º–∏–Ω–≥–∞:
    1. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–º
    2. –í—ã–∑–æ–≤ LLM —á–µ—Ä–µ–∑ –∫–ª–∏–µ–Ω—Ç
    3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ –¥–æ–º–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å
    4. –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏–π
    5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ –¥–æ–º–µ–Ω–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã
    6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∏–º–∞ –¥–ª—è API —Å–ª–æ—è
    
    –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç:
    - –ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ Domain)
    - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ LLM API (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ Infrastructure)
    - HTTP/SSE –ª–æ–≥–∏–∫—É (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ API Layer)
    
    –ê—Ç—Ä–∏–±—É—Ç—ã:
        _llm_client: –ö–ª–∏–µ–Ω—Ç –¥–ª—è –≤—ã–∑–æ–≤–∞ LLM
        _tool_filter: –°–µ—Ä–≤–∏—Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        _response_processor: –°–µ—Ä–≤–∏—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤
        _event_publisher: Publisher –¥–ª—è —Å–æ–±—ã—Ç–∏–π
        _session_service: –°–µ—Ä–≤–∏—Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–µ—Å—Å–∏—è–º–∏
        _hitl_service: –°–µ—Ä–≤–∏—Å HITL
    
    –ü—Ä–∏–º–µ—Ä:
        >>> handler = StreamLLMResponseHandler(
        ...     llm_client=llm_client,
        ...     tool_filter=tool_filter,
        ...     response_processor=response_processor,
        ...     event_publisher=event_publisher,
        ...     session_service=session_service,
        ...     hitl_service=hitl_service
        ... )
        >>> async for chunk in handler.handle(
        ...     session_id="session-1",
        ...     history=[...],
        ...     model="gpt-4"
        ... ):
        ...     print(chunk)
    """
    
    def __init__(
        self,
        llm_client: LLMClient,
        tool_filter: ToolFilterService,
        response_processor: LLMResponseProcessor,
        event_publisher: LLMEventPublisher,
        session_service: SessionManagementService,
        hitl_service: HITLService
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è handler.
        
        Args:
            llm_client: –ö–ª–∏–µ–Ω—Ç –¥–ª—è –≤—ã–∑–æ–≤–∞ LLM
            tool_filter: –°–µ—Ä–≤–∏—Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
            response_processor: –°–µ—Ä–≤–∏—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤
            event_publisher: Publisher –¥–ª—è —Å–æ–±—ã—Ç–∏–π
            session_service: –°–µ—Ä–≤–∏—Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–µ—Å—Å–∏—è–º–∏
            hitl_service: –°–µ—Ä–≤–∏—Å HITL
        """
        self._llm_client = llm_client
        self._tool_filter = tool_filter
        self._response_processor = response_processor
        self._event_publisher = event_publisher
        self._session_service = session_service
        self._hitl_service = hitl_service
        
        logger.info("StreamLLMResponseHandler initialized")
    
    async def handle(
        self,
        session_id: str,
        history: List[Dict[str, Any]],
        model: str,
        allowed_tools: Optional[List[str]] = None,
        correlation_id: Optional[str] = None
    ) -> AsyncGenerator[StreamChunk, None]:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å –Ω–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ LLM.
        
        Use Case:
        1. –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –ø–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–º
        2. –û–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ –Ω–∞—á–∞–ª–∞ –∑–∞–ø—Ä–æ—Å–∞
        3. –í—ã–∑–≤–∞—Ç—å LLM —á–µ—Ä–µ–∑ –∫–ª–∏–µ–Ω—Ç
        4. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ –¥–æ–º–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å
        5. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å tool calls –∏–ª–∏ –æ–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        6. –û–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        7. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–∏–º –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
            history: –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è LLM
            model: –ò–º—è –º–æ–¥–µ–ª–∏
            allowed_tools: –°–ø–∏—Å–æ–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (None = –≤—Å–µ)
            correlation_id: ID –¥–ª—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Yields:
            StreamChunk: –ß–∞–Ω–∫–∏ –¥–ª—è SSE —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
            
        –ü—Ä–∏–º–µ—Ä:
            >>> async for chunk in handler.handle(
            ...     session_id="session-1",
            ...     history=[{"role": "user", "content": "Hello"}],
            ...     model="gpt-4",
            ...     allowed_tools=["read_file", "write_file"]
            ... ):
            ...     if chunk.type == "tool_call":
            ...         print(f"Tool call: {chunk.tool_name}")
            ...     elif chunk.type == "assistant_message":
            ...         print(f"Message: {chunk.content}")
        """
        try:
            # TEMPORARY: –Ø–≤–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            logger.error(
                f"üî• NEW CODE: StreamLLMResponseHandler.handle() called for session {session_id} "
                f"with {len(history)} messages"
            )
            logger.info(
                f"Starting LLM stream for session {session_id} "
                f"with {len(history)} messages"
            )
            
            # 1. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (Domain)
            tools = self._tool_filter.filter_tools(allowed_tools)
            
            # 2. –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è –Ω–∞—á–∞–ª–∞ (Infrastructure)
            await self._event_publisher.publish_request_started(
                session_id=session_id,
                model=model,
                messages_count=len(history),
                tools_count=len(tools),
                correlation_id=correlation_id
            )
            
            # 3. –í—ã–∑–æ–≤ LLM (Infrastructure)
            start_time = time.time()
            response = await self._llm_client.chat_completion(
                model=model,
                messages=history,
                tools=tools
            )
            duration_ms = int((time.time() - start_time) * 1000)
            
            logger.debug(
                f"LLM response received: content_length={len(response.content)}, "
                f"tool_calls={len(response.tool_calls)}, "
                f"duration={duration_ms}ms"
            )
            
            # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ (Domain)
            processed = self._response_processor.process_response(response)
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            if processed.validation_warnings:
                for warning in processed.validation_warnings:
                    logger.warning(f"Validation warning: {warning}")
            
            # 5. –û–±—Ä–∞–±–æ—Ç–∫–∞ tool calls –∏–ª–∏ –æ–±—ã—á–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            if processed.has_tool_calls():
                chunk = await self._handle_tool_call(
                    session_id=session_id,
                    processed=processed,
                    duration_ms=duration_ms,
                    history=history,
                    correlation_id=correlation_id
                )
            else:
                chunk = await self._handle_assistant_message(
                    session_id=session_id,
                    processed=processed,
                    duration_ms=duration_ms,
                    correlation_id=correlation_id
                )
            
            # 6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∏–º–∞
            yield chunk
            
        except Exception as e:
            logger.error(
                f"Exception in stream_response for session {session_id}: {e}",
                exc_info=True
            )
            
            # –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è –æ—à–∏–±–∫–∏
            await self._event_publisher.publish_request_failed(
                session_id=session_id,
                model=model,
                error=str(e),
                correlation_id=correlation_id
            )
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è error chunk
            yield StreamChunk(
                type="error",
                error=str(e),
                is_final=True
            )
    
    async def _handle_tool_call(
        self,
        session_id: str,
        processed: ProcessedResponse,
        duration_ms: int,
        history: List[Dict[str, Any]],
        correlation_id: Optional[str]
    ) -> StreamChunk:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å tool call.
        
        –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è:
        1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∞–≥–µ–Ω—Ç–∞ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
        2. –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è tool execution requested
        3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ pending approval (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
        4. –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è tool approval required (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
        5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Å–µ—Å—Å–∏—é
        6. –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è LLM –∑–∞–ø—Ä–æ—Å–∞
        7. –°–æ–∑–¥–∞–Ω–∏–µ chunk –¥–ª—è —Å—Ç—Ä–∏–º–∞
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
            processed: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç LLM
            duration_ms: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞ –≤ –º—Å
            history: –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π (–¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞)
            correlation_id: ID –¥–ª—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏
            
        Returns:
            StreamChunk –¥–ª—è tool call
        """
        tool_call = processed.get_first_tool_call()
        
        if not tool_call:
            raise ValueError("No tool call found in processed response")
        
        logger.info(
            f"Tool call detected: {tool_call.tool_name} (call_id={tool_call.id})"
        )
        
        # 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∞–≥–µ–Ω—Ç–∞ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
        current_agent = "unknown"
        for msg in reversed(history):
            if msg.get("role") == "assistant" and msg.get("name"):
                current_agent = msg["name"]
                break
        
        # 2. –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è tool execution requested
        await self._event_publisher.publish_tool_execution_requested(
            session_id=session_id,
            tool_name=tool_call.tool_name,
            arguments=tool_call.arguments,
            call_id=tool_call.id,
            agent=current_agent,
            correlation_id=correlation_id
        )
        
        # 3. HITL: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ pending approval (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
        if processed.requires_approval:
            await self._hitl_service.add_pending(
                session_id=session_id,
                call_id=tool_call.id,
                tool_name=tool_call.tool_name,
                arguments=tool_call.arguments,
                reason=processed.approval_reason
            )
            
            logger.info(
                f"Added HITL pending state for call_id={tool_call.id}, "
                f"reason={processed.approval_reason}"
            )
            
            # 4. –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è tool approval required
            await self._event_publisher.publish_tool_approval_required(
                session_id=session_id,
                tool_name=tool_call.tool_name,
                arguments=tool_call.arguments,
                call_id=tool_call.id,
                reason=processed.approval_reason or "Unknown",
                correlation_id=correlation_id
            )
        
        # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ –¥–æ–º–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å
        await self._session_service.add_message(
            session_id=session_id,
            role="assistant",
            content="",
            tool_calls=[tool_call.to_dict()]
        )
        
        logger.debug(
            f"Assistant message with tool_call persisted: {tool_call.tool_name}"
        )
        
        # 6. –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è LLM –∑–∞–ø—Ä–æ—Å–∞
        await self._event_publisher.publish_request_completed(
            session_id=session_id,
            model=processed.model,
            duration_ms=duration_ms,
            usage=processed.usage,
            has_tool_calls=True,
            correlation_id=correlation_id
        )
        
        # 7. –°–æ–∑–¥–∞–Ω–∏–µ chunk –¥–ª—è —Å—Ç—Ä–∏–º–∞
        return StreamChunk(
            type="tool_call",
            call_id=tool_call.id,
            tool_name=tool_call.tool_name,
            arguments=tool_call.arguments,
            requires_approval=processed.requires_approval,
            is_final=True
        )
    
    async def _handle_assistant_message(
        self,
        session_id: str,
        processed: ProcessedResponse,
        duration_ms: int,
        correlation_id: Optional[str]
    ) -> StreamChunk:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.
        
        –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è:
        1. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Å–µ—Å—Å–∏—é
        2. –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è LLM –∑–∞–ø—Ä–æ—Å–∞
        3. –°–æ–∑–¥–∞–Ω–∏–µ chunk –¥–ª—è —Å—Ç—Ä–∏–º–∞
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
            processed: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç LLM
            duration_ms: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞ –≤ –º—Å
            correlation_id: ID –¥–ª—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏
            
        Returns:
            StreamChunk –¥–ª—è assistant message
        """
        logger.info(
            f"Sending assistant message: {len(processed.content)} chars"
        )
        
        # 1. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ –¥–æ–º–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å
        await self._session_service.add_message(
            session_id=session_id,
            role="assistant",
            content=processed.content
        )
        
        # 2. –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        await self._event_publisher.publish_request_completed(
            session_id=session_id,
            model=processed.model,
            duration_ms=duration_ms,
            usage=processed.usage,
            has_tool_calls=False,
            correlation_id=correlation_id
        )
        
        # 3. –°–æ–∑–¥–∞–Ω–∏–µ chunk –¥–ª—è —Å—Ç—Ä–∏–º–∞
        return StreamChunk(
            type="assistant_message",
            content=processed.content,
            token=processed.content,
            is_final=True
        )
